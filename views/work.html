<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Work</title>
    <link rel="icon" type="image/webp" href="../assets/darth-vader-512.webp" />
    <link rel="stylesheet" href="../css/style.css" />
    <link
      href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;700&display=swap"
      rel="stylesheet"
    />
  </head>
  <body>
    <div class="container">
      <div class="name">
        <h2>Utkarsh Bajaj</h2>
      </div>
      <div id="navbar"></div>
      <script src="../scripts/navbar.js"></script>
    </div>
    <hr />
    <div class="content-section">
      <h2>Software Engineering Intern, Amazon</h2>
      <p>
        As a Summer 2025 Software Engineering Intern at Amazon, I worked on
        building an agent-based question-answering system as part of the AWS
        International Expansion team. My primary focus was designing and
        implementing a Retrieval-Augmented Generation (RAG) solution using
        Amazon Bedrock, vector embeddings, and semantic search. This system
        automated responses to compliance-related queries, reducing repeat
        questions sent to downstream teams by up to 50%, and helping cut both
        operational overhead and external costs. This was used in internal
        chatbots.
      </p>

      <p>
        In addition, I developed a mechanism to keep the systemâ€™s data store
        continuously updated (automating conversion of data updates in DynamoDB
        to vector embeddings), allowing it to provide accurate answers despite
        the knowledge cutoff limitations of large language models. This
        contributed to a more reliable and consistent internal tool that
        improved support for global expansion efforts and compliance operations.
      </p>
      <h2>Research Assistant, Carnegie Mellon University</h2>
      <p>
        As a Research Assistant, I contributed to the development of an advanced
        autograding platform for programming assignments, combining static and
        dynamic analysis techniques with Large Language Models (LLMs). Our work
        focused on designing a functional autograder that delivers context-aware
        evaluations by leveraging a dataset of past submissions and instructor
        feedback. The system generates personalized comments and integrates
        directly with IntelliJ through an IDE plugin, enabling students to
        receive immediate feedback with a single click.
      </p>
      <h2>Software Engineer, Microsoft</h2>
      <p>
        As a software engineer at
        <a href="https://learn.microsoft.com/en-us/azure/automation/overview"
          >Azure Automation</a
        >, I worked on migrating PowerShell and Python scripts from a bulky
        VM-based setup to a sleek, containerized microservices architecture
        using .NET and Docker. This migration made things more secure by running
        scripts in isolated Hyper-V containers, improving our success rate from
        99.8% to 99.9% for over 200M executions each month.
      </p>
      <p>
        I built internal APIs and developed custom PowerShell cmdlets and Python
        packages to let customers easily access their Azure assets, like
        credentials and certificates.
      </p>
      <p>
        I also worked on debugging and deploying microservices to support
        communication between containers and servers, which helped us scale to
        new regions. By automating monitoring and deployment scripts, I helped
        cut down on manual work for expanding into additional data centers.
      </p>
      <h2>Software Engineering Intern, Microsoft</h2>
      <p>
        As an intern at
        <a href="https://learn.microsoft.com/en-us/azure/automation/overview"
          >Azure Automation</a
        >
        I developed a C# application, to be executed on containers using .NET
        Core and Docker to add new runtimes of PowerShell 7.2 and Python 3.10,
        designed to be executed on containers. This project involved writing
        over 10,000 lines of code, ensuring quality with 95%+ unit test coverage
        and building in robust failure detection. The new runtimes saw strong
        adoption, with 150+ customers running 10,000+ scripts during the preview
        phase, paving the way for migrating existing Azure Automation runtimes
        to containers.
      </p>
    </div>
  </body>
</html>
